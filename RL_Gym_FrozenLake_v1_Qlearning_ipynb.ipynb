{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "RL_Gym_FrozenLake_Qlearning.ipynb의 사본",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choki0715/lecture/blob/master/RL_Gym_FrozenLake_v1_Qlearning_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLvBREauH5Y5"
      },
      "source": [
        "# Frozen Lake 강화학습 연습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fw_9WoQH5Zi"
      },
      "source": [
        "<img src=\"https://github.com/aidentify/lecture/blob/master/study2/2_RL/img/frozenlake_env.png?raw=1\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9znpsCJH5Zk"
      },
      "source": [
        "## 필요한 모듈 import\n",
        "* gym (가상환경을 제공) \n",
        "* numpy (텐서 연산)\n",
        "* matplotlib (결과 그래프 출력)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBY4hzL4H5Zm"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gym[toy_text]"
      ],
      "metadata": {
        "id": "6ek_8XuyWZBV",
        "outputId": "93ce12d5-a7f9-4ae4-ca21-e11846970456",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[toy_text] in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[toy_text]) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[toy_text]) (5.1.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym[toy_text]) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[toy_text]) (1.5.0)\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 68.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[toy_text]) (3.11.0)\n",
            "Installing collected packages: pygame\n",
            "Successfully installed pygame-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yen8Zl0LH5Z2"
      },
      "source": [
        "## 가상환경 설정 및 hyper parameter 정의\n",
        "* gym.make를 이용하여 등록된 'FrozenLake-v0' 환경을 env로 정의, is_slippery=True $\\rightarrow$ Transition Prob = 1.0\n",
        "* learning rate (학습률)\n",
        "* dis (감쇄계수)\n",
        "* num_episodes(전체 반복 학습)\n",
        "* env.render(): 설정한 가상환경을 보고싶을 때, S: Start, F: Frozen, H: Hole, G: Goal, 붉은 박스: 현재 위치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5R_ygFVH5Z3",
        "outputId": "dbe36e1c-5071-423d-a6a5-a0bfba3728b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#env = gym.make('FrozenLake-v0', is_slippery=False)\n",
        "env = gym.make('FrozenLake-v1', is_slippery=False)\n",
        "\n",
        "import os\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
        "\n",
        "learning_rate = 0.8\n",
        "dis = .95\n",
        "num_episodes = 2000\n",
        "\n",
        "env.reset()\n",
        "env.render()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:49: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
            "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSWlgfQxH5aC"
      },
      "source": [
        "## 펭수가 학습할 가상환경 관찰\n",
        "* info = 상태전이 확률 (if slippery = true, then prob = 0.333333)\n",
        "* env.render(): 설정한 가상환경을 보고싶을 때, S: Start, F: Frozen, H: Hole, G: Goal, 붉은 박스: 현재 위치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wb6O710H5ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d406e1fc-ba8d-4361-c339-9eabfb5a1ba9"
      },
      "source": [
        "env.reset()\n",
        "for i in range(10):\n",
        "    random_action = env.action_space.sample()\n",
        "    new_state, reward, done, info = env.step(random_action)\n",
        "    env.render()\n",
        "    print(new_state, reward, done,  info)\n",
        "    if done:\n",
        "      break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.0 False {'prob': 1.0}\n",
            "1 0.0 False {'prob': 1.0}\n",
            "0 0.0 False {'prob': 1.0}\n",
            "0 0.0 False {'prob': 1.0}\n",
            "1 0.0 False {'prob': 1.0}\n",
            "2 0.0 False {'prob': 1.0}\n",
            "2 0.0 False {'prob': 1.0}\n",
            "3 0.0 False {'prob': 1.0}\n",
            "3 0.0 False {'prob': 1.0}\n",
            "3 0.0 False {'prob': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3V5YCY5H5aw"
      },
      "source": [
        "## Q-Table 및 보상값 리스트 정의\n",
        "* Q = Q-Table [num_states, num_actions]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZalfqntH5ax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9954958d-b6ff-4690-a606-b11f0faa0788"
      },
      "source": [
        "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "rList = []\n",
        "\n",
        "print(\"number of states: \", env.observation_space.n)\n",
        "print(\"number of actions: \", env.action_space.n)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of states:  16\n",
            "number of actions:  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2LwfZn3H5a4"
      },
      "source": [
        "## 학습 시작\n",
        "* num_episodes 만큼 반복\n",
        "* 한번 에피소드 당 99번 반복하거나 terminal state (Hole, Goal)에 도착하면 다음 에피소드로\n",
        "*  $\\epsilon$ - greedy를 적용하여  $\\epsilon$ = 1/(n+1) 확률 만큼 maxQ(s,a)가 아닌 액션을 취함 (이때 n은 100번 에피소스마다 1씩 증가)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUJmAfskH5a6"
      },
      "source": [
        "for i in range(num_episodes):\n",
        "    \n",
        "    # env 리셋\n",
        "    state = env.reset()\n",
        "    rAll = 0\n",
        "    done = False\n",
        "    \n",
        "    e = 1./((i//100)+1) # decaying E-greedy\n",
        "    \n",
        "    j = 0\n",
        "    \n",
        "    # 99번 반복하거나 terminal state (Hole, Goal) 도착\n",
        "    while j < 99:\n",
        "        \n",
        "        j += 1\n",
        "        \n",
        "        # egreedy에 의한 행동 설정\n",
        "        if np.random.rand(1) < e:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(Q[state, :])\n",
        "\n",
        "        # new_state, reward 업데이트 \n",
        "        new_state, reward, done, _ = env.step(action)\n",
        "        \n",
        "        # 업데이트 Q-table (상태, 행동)\n",
        "        Q[state, action] += learning_rate*( reward + dis*np.max(Q[new_state, :]) - Q[state, action] )\n",
        "        \n",
        "        rAll += reward\n",
        "        state = new_state\n",
        "\n",
        "        if done == True:\n",
        "            break\n",
        "        \n",
        "    rList.append(rAll)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KIIdYDxH5bB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "outputId": "1d0ac27e-b98c-413c-c283-e7db64075362"
      },
      "source": [
        "print('성공율: ', str(sum(rList)/num_episodes))\n",
        "print('Q-table')\n",
        "print(Q)\n",
        "plt.bar(range(len(rList)), rList, color = 'blue')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "성공율:  0.7925\n",
            "Q-table\n",
            "[[0.73509189 0.77378094 0.6983373  0.73509189]\n",
            " [0.73509189 0.         0.64016809 0.69833717]\n",
            " [0.67040099 0.850516   0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.77378094 0.81450625 0.         0.73509189]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.9025     0.         0.6255408 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.81450625 0.         0.857375   0.77378094]\n",
            " [0.81450625 0.90249998 0.9025     0.        ]\n",
            " [0.857375   0.95       0.         0.857375  ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.81449548 0.95       0.857375  ]\n",
            " [0.9025     0.95       1.         0.9025    ]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwVNF-swH5bU"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}