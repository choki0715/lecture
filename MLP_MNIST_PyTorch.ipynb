{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyP0uLe+RIn8FhvSIpArIDdm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choki0715/lecture/blob/master/MLP_MNIST_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkZoP2JHvoFD",
        "outputId": "67f37da4-9f00-43a6-8e16-df6017ba921b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 31.7MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 1.06MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 9.78MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 17.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            "ì´ íŒŒë¼ë¯¸í„° ìˆ˜: 535,818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# 2ê°œì˜ ì€ë‹‰ì¸µì„ ê°€ì§„ MLP ëª¨ë¸ ì •ì˜\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size=784, hidden1_size=512, hidden2_size=256, num_classes=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden2_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ìž…ë ¥ ì´ë¯¸ì§€ë¥¼ 1ì°¨ì›ìœ¼ë¡œ íŽ¼ì¹˜ê¸°\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # ì²« ë²ˆì§¸ ì€ë‹‰ì¸µ\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        # ë‘ ë²ˆì§¸ ì€ë‹‰ì¸µ\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        # ì¶œë ¥ì¸µ\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# ë°ì´í„° ì „ì²˜ë¦¬\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST í‰ê· ê³¼ í‘œì¤€íŽ¸ì°¨\n",
        "])\n",
        "\n",
        "# MNIST ë°ì´í„°ì…‹ ë¡œë“œ\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "model = MLP().to(device)\n",
        "print(model)\n",
        "print(f'\\nì´ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# í•™ìŠµ í•¨ìˆ˜\n",
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # ìˆœì „íŒŒ\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # ì—­ì „íŒŒ\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # í†µê³„ ê³„ì‚°\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = output.max(1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target).sum().item()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
        "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    avg_loss = train_loss / len(train_loader)\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n",
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            _, predicted = output.max(1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, '\n",
        "          f'Accuracy: {correct}/{total} ({accuracy:.2f}%)\\n')\n",
        "\n",
        "    return test_loss, accuracy\n",
        "\n",
        "# í•™ìŠµ ì‹¤í–‰\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "print('í•™ìŠµ ì‹œìž‘...\\n')\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss, train_acc = train(model, device, train_loader, optimizer, criterion, epoch)\n",
        "    test_loss, test_acc = test(model, device, test_loader, criterion)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkIv1dLNvyFF",
        "outputId": "85e978aa-6e56-4c8c-e4f9-f5b6182c29c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í•™ìŠµ ì‹œìž‘...\n",
            "\n",
            "Epoch: 1 [0/60000 (0%)]\tLoss: 2.295684\n",
            "Epoch: 1 [12800/60000 (21%)]\tLoss: 0.226062\n",
            "Epoch: 1 [25600/60000 (43%)]\tLoss: 0.222512\n",
            "Epoch: 1 [38400/60000 (64%)]\tLoss: 0.117284\n",
            "Epoch: 1 [51200/60000 (85%)]\tLoss: 0.095173\n",
            "\n",
            "Test set: Average loss: 0.1085, Accuracy: 9646/10000 (96.46%)\n",
            "\n",
            "Epoch: 2 [0/60000 (0%)]\tLoss: 0.061509\n",
            "Epoch: 2 [12800/60000 (21%)]\tLoss: 0.022178\n",
            "Epoch: 2 [25600/60000 (43%)]\tLoss: 0.042374\n",
            "Epoch: 2 [38400/60000 (64%)]\tLoss: 0.036901\n",
            "Epoch: 2 [51200/60000 (85%)]\tLoss: 0.078590\n",
            "\n",
            "Test set: Average loss: 0.0972, Accuracy: 9705/10000 (97.05%)\n",
            "\n",
            "Epoch: 3 [0/60000 (0%)]\tLoss: 0.079712\n",
            "Epoch: 3 [12800/60000 (21%)]\tLoss: 0.047117\n",
            "Epoch: 3 [25600/60000 (43%)]\tLoss: 0.017512\n",
            "Epoch: 3 [38400/60000 (64%)]\tLoss: 0.020257\n",
            "Epoch: 3 [51200/60000 (85%)]\tLoss: 0.035660\n",
            "\n",
            "Test set: Average loss: 0.0720, Accuracy: 9768/10000 (97.68%)\n",
            "\n",
            "Epoch: 4 [0/60000 (0%)]\tLoss: 0.044682\n",
            "Epoch: 4 [12800/60000 (21%)]\tLoss: 0.079537\n",
            "Epoch: 4 [25600/60000 (43%)]\tLoss: 0.018016\n",
            "Epoch: 4 [38400/60000 (64%)]\tLoss: 0.037837\n",
            "Epoch: 4 [51200/60000 (85%)]\tLoss: 0.126574\n",
            "\n",
            "Test set: Average loss: 0.0892, Accuracy: 9732/10000 (97.32%)\n",
            "\n",
            "Epoch: 5 [0/60000 (0%)]\tLoss: 0.061852\n",
            "Epoch: 5 [12800/60000 (21%)]\tLoss: 0.001844\n",
            "Epoch: 5 [25600/60000 (43%)]\tLoss: 0.006158\n",
            "Epoch: 5 [38400/60000 (64%)]\tLoss: 0.067829\n",
            "Epoch: 5 [51200/60000 (85%)]\tLoss: 0.010290\n",
            "\n",
            "Test set: Average loss: 0.0808, Accuracy: 9757/10000 (97.57%)\n",
            "\n",
            "Epoch: 6 [0/60000 (0%)]\tLoss: 0.033050\n",
            "Epoch: 6 [12800/60000 (21%)]\tLoss: 0.017964\n",
            "Epoch: 6 [25600/60000 (43%)]\tLoss: 0.129066\n",
            "Epoch: 6 [38400/60000 (64%)]\tLoss: 0.017965\n",
            "Epoch: 6 [51200/60000 (85%)]\tLoss: 0.061271\n",
            "\n",
            "Test set: Average loss: 0.0841, Accuracy: 9770/10000 (97.70%)\n",
            "\n",
            "Epoch: 7 [0/60000 (0%)]\tLoss: 0.063744\n",
            "Epoch: 7 [12800/60000 (21%)]\tLoss: 0.012940\n",
            "Epoch: 7 [25600/60000 (43%)]\tLoss: 0.045138\n",
            "Epoch: 7 [38400/60000 (64%)]\tLoss: 0.012290\n",
            "Epoch: 7 [51200/60000 (85%)]\tLoss: 0.118009\n",
            "\n",
            "Test set: Average loss: 0.0847, Accuracy: 9777/10000 (97.77%)\n",
            "\n",
            "Epoch: 8 [0/60000 (0%)]\tLoss: 0.009727\n",
            "Epoch: 8 [12800/60000 (21%)]\tLoss: 0.005862\n",
            "Epoch: 8 [25600/60000 (43%)]\tLoss: 0.043743\n",
            "Epoch: 8 [38400/60000 (64%)]\tLoss: 0.096017\n",
            "Epoch: 8 [51200/60000 (85%)]\tLoss: 0.018443\n",
            "\n",
            "Test set: Average loss: 0.0823, Accuracy: 9789/10000 (97.89%)\n",
            "\n",
            "Epoch: 9 [0/60000 (0%)]\tLoss: 0.016029\n",
            "Epoch: 9 [12800/60000 (21%)]\tLoss: 0.017346\n",
            "Epoch: 9 [25600/60000 (43%)]\tLoss: 0.014246\n",
            "Epoch: 9 [38400/60000 (64%)]\tLoss: 0.035608\n",
            "Epoch: 9 [51200/60000 (85%)]\tLoss: 0.005476\n",
            "\n",
            "Test set: Average loss: 0.0794, Accuracy: 9801/10000 (98.01%)\n",
            "\n",
            "Epoch: 10 [0/60000 (0%)]\tLoss: 0.005480\n",
            "Epoch: 10 [12800/60000 (21%)]\tLoss: 0.004944\n",
            "Epoch: 10 [25600/60000 (43%)]\tLoss: 0.001463\n",
            "Epoch: 10 [38400/60000 (64%)]\tLoss: 0.002549\n",
            "Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000610\n",
            "\n",
            "Test set: Average loss: 0.0747, Accuracy: 9812/10000 (98.12%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ê²°ê³¼ ì‹œê°í™”\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# ì†ì‹¤ ê·¸ëž˜í”„\n",
        "ax1.plot(range(1, num_epochs + 1), train_losses, label='Train Loss', marker='o')\n",
        "ax1.plot(range(1, num_epochs + 1), test_losses, label='Test Loss', marker='s')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training and Test Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# ì •í™•ë„ ê·¸ëž˜í”„\n",
        "ax2.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy', marker='o')\n",
        "ax2.plot(range(1, num_epochs + 1), test_accuracies, label='Test Accuracy', marker='s')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.set_title('Training and Test Accuracy')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/mnt/user-data/outputs/training_results.png', dpi=300, bbox_inches='tight')\n",
        "print('í•™ìŠµ ê²°ê³¼ ê·¸ëž˜í”„ê°€ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.')\n",
        "\n",
        "# ëª¨ë¸ ì €ìž¥\n",
        "torch.save(model.state_dict(), '/mnt/user-data/outputs/mnist_mlp.pth')\n",
        "print('ëª¨ë¸ì´ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.')\n",
        "\n",
        "# ì˜ˆì¸¡ ìƒ˜í”Œ ì‹œê°í™”\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìƒ˜í”Œ ì¶”ì¶œ\n",
        "    data_iter = iter(test_loader)\n",
        "    images, labels = next(data_iter)\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # ì˜ˆì¸¡\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # ì²˜ìŒ 10ê°œ ìƒ˜í”Œ ì‹œê°í™”\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "    for idx, ax in enumerate(axes.flat):\n",
        "        img = images[idx].cpu().squeeze()\n",
        "        ax.imshow(img, cmap='gray')\n",
        "        ax.set_title(f'ì˜ˆì¸¡: {predicted[idx].item()}\\nì‹¤ì œ: {labels[idx].item()}',\n",
        "                    color='green' if predicted[idx] == labels[idx] else 'red')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/mnt/user-data/outputs/predictions.png', dpi=300, bbox_inches='tight')\n",
        "    print('ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”ê°€ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.')\n",
        "\n",
        "print(f'\\nìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracies[-1]:.2f}%')"
      ],
      "metadata": {
        "id": "DyhZf_Yzv9Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” (ìš”ì²­í•˜ì‹  ì½”ë“œ ì ìš©)\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ì¤‘...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model.eval()\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.to(device)  # Move images to the device\n",
        "\n",
        "# get sample outputs\n",
        "output = model(images)\n",
        "# convert output probabilities to predicted class\n",
        "_, preds = torch.max(output, 1)\n",
        "# prep images for display\n",
        "images = images.cpu().numpy()  # Move images back to CPU for numpy conversion\n",
        "\n",
        "# plot the images in the batch, along with predicted and true labels\n",
        "fig = plt.figure(figsize=(16, 16))\n",
        "for idx in np.arange(36):\n",
        "    ax = fig.add_subplot(6, 6, idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "    ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),\n",
        "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"),\n",
        "                 fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Prediction Results (Predicted (True Label))\\nGreen: Correct, Red: Incorrect',\n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/mnt/user-data/outputs/predictions_visualization.png', dpi=150, bbox_inches='tight')\n",
        "print(\"ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”ê°€ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤: predictions_visualization.png\")\n",
        "\n",
        "# ì •í™•ë„ í†µê³„\n",
        "correct_predictions = (preds == labels.to(device)).sum().item()\n",
        "total_predictions = len(labels)\n",
        "accuracy_batch = 100. * correct_predictions / total_predictions\n",
        "print(f\"\\nì´ ë°°ì¹˜ì˜ ì •í™•ë„: {correct_predictions}/{total_predictions} = {accuracy_batch:.2f}%\")\n",
        "\n",
        "# ì˜¤ë¶„ë¥˜ëœ ìƒ˜í”Œ ë¶„ì„\n",
        "misclassified = []\n",
        "for idx in range(len(preds)):\n",
        "    if preds[idx] != labels[idx]:\n",
        "        misclassified.append({\n",
        "            'index': idx,\n",
        "            'predicted': preds[idx].item(),\n",
        "            'true': labels[idx].item()\n",
        "        })\n",
        "\n",
        "if misclassified:\n",
        "    print(f\"\\nì˜¤ë¶„ë¥˜ëœ ìƒ˜í”Œ: {len(misclassified)}ê°œ\")\n",
        "    print(\"ì²˜ìŒ 5ê°œì˜ ì˜¤ë¶„ë¥˜:\")\n",
        "    for i, mis in enumerate(misclassified[:5]):\n",
        "        print(f\"  {i+1}. ì¸ë±ìŠ¤ {mis['index']}: ì˜ˆì¸¡={mis['predicted']}, ì‹¤ì œ={mis['true']}\")\n",
        "else:\n",
        "    print(\"\\nì´ ë°°ì¹˜ì—ì„œ ëª¨ë“  ì˜ˆì¸¡ì´ ì •í™•í•©ë‹ˆë‹¤! ðŸŽ‰\")\n",
        "\n",
        "# í˜¼ë™ í–‰ë ¬ ìƒì„± (ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ í˜¼ë™ í–‰ë ¬ ìƒì„± ì¤‘...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(device)\n",
        "        output = model(data)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(target.numpy())\n",
        "\n",
        "# í˜¼ë™ í–‰ë ¬\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# í˜¼ë™ í–‰ë ¬ ì‹œê°í™”\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=range(10), yticklabels=range(10))\n",
        "plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/mnt/user-data/outputs/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "print(\"í˜¼ë™ í–‰ë ¬ì´ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤: confusion_matrix.png\")\n",
        "\n",
        "# ë¶„ë¥˜ ë¦¬í¬íŠ¸\n",
        "print(\"\\në¶„ë¥˜ ë¦¬í¬íŠ¸:\")\n",
        "print(classification_report(all_labels, all_preds,\n",
        "                          target_names=[str(i) for i in range(10)]))\n",
        "\n",
        "# ëª¨ë¸ ì €ìž¥\n",
        "torch.save(model.state_dict(), '/mnt/user-data/outputs/mnist_cnn_model.pth')\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ëª¨ë¸ì´ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤: mnist_cnn_model.pth\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nâœ… ëª¨ë“  ìž‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "print(\"\\nìƒì„±ëœ íŒŒì¼:\")\n",
        "print(\"  1. training_history.png - í•™ìŠµ ê³¡ì„ \")\n",
        "print(\"  2. predictions_visualization.png - 36ê°œ ìƒ˜í”Œ ì˜ˆì¸¡ ê²°ê³¼\")\n",
        "print(\"  3. confusion_matrix.png - í˜¼ë™ í–‰ë ¬\")\n",
        "print(\"  4. mnist_cnn_model.pth - í•™ìŠµëœ ëª¨ë¸\")"
      ],
      "metadata": {
        "id": "zne-ymR37CHg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}