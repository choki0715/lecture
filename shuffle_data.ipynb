{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shuffle_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNewj2sGSECk/8M0EGhqV6p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choki0715/lecture/blob/master/shuffle_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBV8I4_KSR5L"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "x_data, y_data = dataset_build(dataset, dataset[:, 1], 0,\r\n",
        "                                  data_len, input_size,\r\n",
        "                                  target_size, STEP, d_model)\r\n",
        "\r\n",
        "\r\n",
        "# Creating training and validation sets using an 80-20 split\r\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(x_data, y_data, test_size=0.3)\r\n",
        "\r\n",
        "# Show length\r\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\r\n",
        "\r\n",
        "\r\n",
        "BUFFER_SIZE_TRAIN = len(input_tensor_train)\r\n",
        "BUFFER_SIZE_VAL = len(input_tensor_val)\r\n",
        "\r\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\r\n",
        "embedding_dim = 128\r\n",
        "units = 128\r\n",
        "vocab_size = 500\r\n",
        "\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE_TRAIN)\r\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\r\n",
        "\r\n",
        "val_set = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(BUFFER_SIZE_VAL)\r\n",
        "\r\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\r\n",
        "print('example_input_batch.shape ', example_input_batch.shape)\r\n",
        "print('example_target_batch.shape ', example_target_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}