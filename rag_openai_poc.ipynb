{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZZtUJnGlxp9Fe+biSiiXS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choki0715/lecture/blob/master/rag_openai_poc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NyTOGfO2Ur1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI  # OpenAIë¡œ ë³€ê²½\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import streamlit as st\n",
        "import tempfile\n",
        "\n",
        "# OpenAI API í‚¤ ì„¤ì •\n",
        "os.environ['OPENAI_API_KEY'] = \"\"  # ì‹¤ì œ API í‚¤ë¡œ ë³€ê²½\n",
        "\n",
        "###########################################################################\n",
        "# streamlit UI\n",
        "# webpage ê·œê²© ë° ë””ìì¸\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.markdown(\"<h1 style='text-align: center; color: gray;'>ì¸êµ¬ê°ì†Œ ëŒ€ì‘ ì •ì±…ì„ ìœ„í•œ RAG System</h1>\", unsafe_allow_html=True)\n",
        "st.markdown(\"<h2 style='text-align: center; color: gray;'> Chat with PDFs that you upload </h2>\", unsafe_allow_html=True)\n",
        "st.markdown(\"<h5 style='text-align: center; color: gray;'>OpenAI GPT ê¸°ë°˜ (ë¹ ë¦„)</h5>\", unsafe_allow_html=True)\n",
        "st.markdown(\"<h3 style='text-align: center; color: gray;'> AIDENTIFY Inc.</h3>\", unsafe_allow_html=True)\n",
        "\n",
        "# streamlit UI\n",
        "###########################################################################\n",
        "\n",
        "def document_data(query, chat_history, vectorstore):\n",
        "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "\n",
        "    # OpenAI LLM ì‚¬ìš© (ë¹ ë¦„)\n",
        "    llm = ChatOpenAI(\n",
        "        model=\"gpt-3.5-turbo\",  # ë˜ëŠ” \"gpt-4o-mini\" (ë” ì €ë ´)\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    qna = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        memory=memory\n",
        "    )\n",
        "\n",
        "    return qna({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # OpenAI ì„ë² ë”© ì‚¬ìš© (ë§¤ìš° ë¹ ë¦„)\n",
        "    embeddings = OpenAIEmbeddings(\n",
        "        model=\"text-embedding-3-small\"  # ë¹ ë¥´ê³  ì €ë ´\n",
        "    )\n",
        "\n",
        "    uploaded_files = st.file_uploader(\"Choose a PDF file\", type=\"pdf\", accept_multiple_files=True)\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=100,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "    )\n",
        "\n",
        "    temp_dir = tempfile.TemporaryDirectory()\n",
        "    docs = []\n",
        "\n",
        "    for i, uploaded_file in enumerate(uploaded_files):\n",
        "        st.write(\"filename:\", i, uploaded_file.name)\n",
        "        temp_filepath = os.path.join(temp_dir.name, uploaded_file.name)\n",
        "        with open(temp_filepath, \"wb\") as f:\n",
        "            f.write(uploaded_file.getvalue())\n",
        "\n",
        "        loader = PyPDFLoader(temp_filepath)\n",
        "        docs.extend(loader.load())\n",
        "\n",
        "    if docs:\n",
        "        with st.spinner(\"ğŸ”¨ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ëŠ” ì¤‘...\"):\n",
        "            split_text = text_splitter.split_documents(documents=docs)\n",
        "            vectorstore = FAISS.from_documents(split_text, embedding=embeddings)\n",
        "\n",
        "        st.success(\"âœ… PDF ì—…ë¡œë“œ ë° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì™„ë£Œ!\")\n",
        "\n",
        "        st.header(':blue[ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”]', divider='rainbow')\n",
        "        prompt = st.chat_input(\"Enter your questions here\")\n",
        "\n",
        "        if \"user_prompt_history\" not in st.session_state:\n",
        "            st.session_state[\"user_prompt_history\"] = []\n",
        "        if \"chat_answers_history\" not in st.session_state:\n",
        "            st.session_state[\"chat_answers_history\"] = []\n",
        "        if \"chat_history\" not in st.session_state:\n",
        "            st.session_state[\"chat_history\"] = []\n",
        "\n",
        "        if prompt:\n",
        "            with st.spinner(\"ğŸ¤” ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘...\"):\n",
        "                output = document_data(\n",
        "                    query=prompt,\n",
        "                    chat_history=st.session_state[\"chat_history\"],\n",
        "                    vectorstore=vectorstore\n",
        "                )\n",
        "\n",
        "                st.session_state[\"chat_answers_history\"].append(output['answer'])\n",
        "                st.session_state[\"user_prompt_history\"].append(prompt)\n",
        "                st.session_state[\"chat_history\"].append((prompt, output['answer']))\n",
        "\n",
        "        if st.session_state[\"chat_answers_history\"]:\n",
        "            for i, j in zip(st.session_state[\"chat_answers_history\"],\n",
        "                          st.session_state[\"user_prompt_history\"]):\n",
        "                message1 = st.chat_message(\"user\")\n",
        "                message1.write(j)\n",
        "                message2 = st.chat_message(\"assistant\")\n",
        "                message2.write(i)"
      ]
    }
  ]
}